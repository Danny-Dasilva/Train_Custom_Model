{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copie de EdgeTPU with Keras",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Danny-Dasilva/Train_Custom_Model/blob/master/Copie_de_EdgeTPU_with_Keras1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auEGoMDKW8Z7",
        "colab_type": "text"
      },
      "source": [
        "Build a model by using Keras and convert it to the Edge TPU tflite file.\n",
        "\n",
        "### Install EdgeTPU Compiler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLXmBB9bQoT7",
        "colab_type": "code",
        "outputId": "f5c32a8e-9865-4e55-d357-774335cd6432",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "source": [
        "%%bash\n",
        "\n",
        "echo \"deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\" | sudo tee /etc/apt/sources.list.d/coral-edgetpu.list\n",
        "sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 6A030B21BA07F4FB\n",
        "\n",
        "sudo apt update > /dev/null\n",
        "sudo apt install edgetpu > /dev/null"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\n",
            "Executing: /tmp/apt-key-gpghome.p74GU8Z3f4/gpg.1.sh --keyserver keyserver.ubuntu.com --recv-keys 6A030B21BA07F4FB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Warning: apt-key output should not be parsed (stdout is not a terminal)\n",
            "gpg: key 6A030B21BA07F4FB: public key \"Google Cloud Packages Automatic Signing Key <gc-team@google.com>\" imported\n",
            "gpg: Total number processed: 1\n",
            "gpg:               imported: 1\n",
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDYJKuhfRoyo",
        "colab_type": "text"
      },
      "source": [
        "## Edge TPU with Keras\n",
        "\n",
        "build very simple model in this notebook.\n",
        "\n",
        "- data: Fashion MNISt\n",
        "- input shape: 28 x 28\n",
        "- output shape: 10\n",
        "- hidden layers: only 1 dense layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aluRnFKRN9y",
        "colab_type": "code",
        "outputId": "bba8c2f9-0cca-44a3-c811-04180795f15f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOPXkm4RQZdv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7efa60c9-a710-4d05-cb96-7ac7f9faa7ba"
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qj9l_kFpQa5X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XT7bDONQi8R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0a4c3b9b-e145-48a4-b321-3d5fc5513da8"
      },
      "source": [
        "print(train_images.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p40JjhzMSU92",
        "colab_type": "code",
        "outputId": "f2b95ece-d9f6-4786-bf92-16ffb2cd310e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "train_images = np.reshape(train_images, [-1, 28, 28, 1])\n",
        "test_images = np.reshape(test_images, [-1, 28, 28, 1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhC7xCG6S-yD",
        "colab_type": "text"
      },
      "source": [
        "### Build the model\n",
        "\n",
        "- define build_keras_model function since we have to build model 2 times (for train and eval)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNuqMwp5f_GX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_keras_model():\n",
        "    return keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(16, kernel_size=3, activation=\"relu\", padding=\"same\", use_bias=False, input_shape=(32, 32, 3)),\n",
        "        keras.layers.BatchNormalization(fused=False),\n",
        "        tf.keras.layers.Conv2D(32, kernel_size=3, strides=2, activation=\"relu\", padding=\"same\", use_bias=False),\n",
        "        keras.layers.BatchNormalization(fused=False),\n",
        "        tf.keras.layers.Conv2D(64, kernel_size=3, strides=2, activation=\"relu\", padding=\"same\", use_bias=False),\n",
        "        tf.keras.layers.AveragePooling2D(pool_size=7),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        keras.layers.Dense(10, activation='softmax')\n",
        "    ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Vk9oFSZXLl-",
        "colab_type": "text"
      },
      "source": [
        "## Train model and save it's checkpoints\n",
        "\n",
        "- Use new Session and Graph to ensure that we can use absolutory same name of variables for train and eval phase.\n",
        "- call `tf.contrib.quantize.create_training_graph` after building model since we want to do Quantization Aware Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUuyAcC8ypv6",
        "colab_type": "code",
        "outputId": "417ffa1c-55d4-426e-bd77-99a7ed635d50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        }
      },
      "source": [
        "# train\n",
        "train_graph = tf.Graph()\n",
        "train_sess = tf.Session(graph=train_graph)\n",
        "\n",
        "keras.backend.set_session(train_sess)\n",
        "with train_graph.as_default():\n",
        "    train_model = build_keras_model()\n",
        "    \n",
        "    tf.contrib.quantize.create_training_graph(input_graph=train_graph, quant_delay=100)\n",
        "    train_sess.run(tf.global_variables_initializer())    \n",
        "\n",
        "    train_model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    train_model.fit(train_images, train_labels, epochs=5)\n",
        "    \n",
        "    # save graph and checkpoints\n",
        "    saver = tf.train.Saver()\n",
        "    saver.save(train_sess, 'checkpoints')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "INFO:tensorflow:Inserting fake quant op activation_Mul_quant after batch_normalization/batchnorm/mul_1\n",
            "INFO:tensorflow:Inserting fake quant op activation_Add_quant after batch_normalization/batchnorm/add_1\n",
            "INFO:tensorflow:Inserting fake quant op activation_Mul_quant after batch_normalization_1/batchnorm/mul_1\n",
            "INFO:tensorflow:Inserting fake quant op activation_Add_quant after batch_normalization_1/batchnorm/add_1\n",
            "Epoch 1/5\n",
            "50000/50000 [==============================] - 32s 645us/sample - loss: 1.6782 - acc: 0.3823\n",
            "Epoch 2/5\n",
            "50000/50000 [==============================] - 29s 588us/sample - loss: 1.4178 - acc: 0.4879\n",
            "Epoch 3/5\n",
            "50000/50000 [==============================] - 30s 595us/sample - loss: 1.3070 - acc: 0.5321\n",
            "Epoch 4/5\n",
            "50000/50000 [==============================] - 30s 595us/sample - loss: 1.2355 - acc: 0.5597\n",
            "Epoch 5/5\n",
            "50000/50000 [==============================] - 30s 592us/sample - loss: 1.1766 - acc: 0.5826\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWp9_I06ZjDo",
        "colab_type": "code",
        "outputId": "c692b4ca-3e44-435b-a94a-5ec4ac182835",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "with train_graph.as_default():\n",
        "    print('sample result of original model')\n",
        "    print(train_model.predict(test_images[:1]))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample result of original model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FailedPreconditionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-1e49460d67b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtrain_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sample result of original model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1076\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m           \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1078\u001b[0;31m           callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1079\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFailedPreconditionError\u001b[0m: Error while reading resource variable dense/kernel from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/dense/kernel/N10tensorflow3VarE does not exist.\n\t [[{{node dense/MatMul/ReadVariableOp}}]]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYOBvXw6X03l",
        "colab_type": "text"
      },
      "source": [
        "### Freeze model and save it\n",
        "\n",
        "- Create new Session and Graph\n",
        "- Call `tf.contrib.quantize.create_eval_graph` and get graph_def after building model before saver.restore\n",
        "- Call `saver.restore` to load the trained weights.\n",
        "   - saver.restore may add unneeded variables to the graph. So we have to get the graph_def before save.restore is called.\n",
        "- We can use `tf.graph_util.convert_variables_to_constants` to freeze the graph_def"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tI1s0JngKN0",
        "colab_type": "code",
        "outputId": "c1705c34-0e34-4433-c486-41129cf501ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "source": [
        "# eval\n",
        "eval_graph = tf.Graph()\n",
        "eval_sess = tf.Session(graph=eval_graph)\n",
        "\n",
        "keras.backend.set_session(eval_sess)\n",
        "\n",
        "with eval_graph.as_default():\n",
        "    keras.backend.set_learning_phase(0)\n",
        "    eval_model = build_keras_model()\n",
        "    tf.contrib.quantize.create_eval_graph(input_graph=eval_graph)\n",
        "    eval_graph_def = eval_graph.as_graph_def()\n",
        "    saver = tf.train.Saver()\n",
        "    saver.restore(eval_sess, 'checkpoints')\n",
        "\n",
        "    frozen_graph_def = tf.graph_util.convert_variables_to_constants(\n",
        "        eval_sess,\n",
        "        eval_graph_def,\n",
        "        [eval_model.output.op.name]\n",
        "    )\n",
        "\n",
        "    with open('frozen_model.pb', 'wb') as f:\n",
        "        f.write(frozen_graph_def.SerializeToString())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Inserting fake quant op activation_Mul_quant after batch_normalization/batchnorm/mul_1\n",
            "INFO:tensorflow:Inserting fake quant op activation_Add_quant after batch_normalization/batchnorm/add_1\n",
            "INFO:tensorflow:Inserting fake quant op activation_Mul_quant after batch_normalization_1/batchnorm/mul_1\n",
            "INFO:tensorflow:Inserting fake quant op activation_Add_quant after batch_normalization_1/batchnorm/add_1\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from checkpoints\n",
            "WARNING:tensorflow:From <ipython-input-13-995fccbe9e12>:17: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/graph_util_impl.py:270: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 37 variables.\n",
            "INFO:tensorflow:Converted 37 variables to const ops.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tETygOV_Y_cX",
        "colab_type": "text"
      },
      "source": [
        "### Generate tflite file\n",
        "\n",
        "- use QUANTIZED_UINT8 option\n",
        "- Quantization Aware training adds min/max information. So we don't need  default_ranges_min default_ranges_max \n",
        "- We don't need call freeze_graph.py since the graph is already freezed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APsbHmt7izT8",
        "colab_type": "code",
        "outputId": "20cfbb75-07e8-40dc-d517-f0e72adb569c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 784
        }
      },
      "source": [
        "%%bash\n",
        "\n",
        "tflite_convert \\\n",
        "    --output_file=model.tflite \\\n",
        "    --graph_def_file=frozen_model.pb \\\n",
        "    --inference_type=QUANTIZED_UINT8 \\\n",
        "    --input_arrays=conv2d_input \\\n",
        "    --output_arrays=dense/Softmax \\\n",
        "    --mean_values=0 \\\n",
        "    --std_dev_values=255"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-10-02 21:00:15.052071: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2019-10-02 21:00:15.082148: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-02 21:00:15.082949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-10-02 21:00:15.083284: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-10-02 21:00:15.084647: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-10-02 21:00:15.085943: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-10-02 21:00:15.086402: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-10-02 21:00:15.094131: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-10-02 21:00:15.095397: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-10-02 21:00:15.109347: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-10-02 21:00:15.109502: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-02 21:00:15.110384: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-02 21:00:15.111081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-10-02 21:00:15.133860: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-10-02 21:00:15.134374: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556e71ed5b80 executing computations on platform Host. Devices:\n",
            "2019-10-02 21:00:15.134409: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-10-02 21:00:15.186938: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-02 21:00:15.187834: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556e767ca380 executing computations on platform CUDA. Devices:\n",
            "2019-10-02 21:00:15.187864: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-10-02 21:00:15.188047: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-02 21:00:15.188844: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-10-02 21:00:15.188895: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-10-02 21:00:15.188916: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-10-02 21:00:15.188932: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-10-02 21:00:15.188948: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-10-02 21:00:15.188966: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-10-02 21:00:15.188981: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-10-02 21:00:15.188998: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-10-02 21:00:15.189067: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-02 21:00:15.189791: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-02 21:00:15.190553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-10-02 21:00:15.196163: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-10-02 21:00:15.197576: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-10-02 21:00:15.197629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-10-02 21:00:15.197649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-10-02 21:00:15.203976: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-02 21:00:15.204836: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-02 21:00:15.205565: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-10-02 21:00:15.205622: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10555 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIKWO5MuZk8f",
        "colab_type": "text"
      },
      "source": [
        "### Check generated tflite file.\n",
        ".\n",
        "- Use TFLiteInterpreter to check the generated file is valid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zI0zfQTL-p5U",
        "colab_type": "code",
        "outputId": "25991416-1824-40da-f422-5c2064b14d7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# load TFLite file\n",
        "interpreter = tf.lite.Interpreter(model_path=f'model.tflite')\n",
        "# Allocate memory. \n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# get some informations .\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "print(input_details)\n",
        "print(output_details)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'name': 'conv2d_input', 'index': 18, 'shape': array([ 1, 32, 32,  3], dtype=int32), 'dtype': <class 'numpy.uint8'>, 'quantization': (0.003921568859368563, 0)}]\n",
            "[{'name': 'dense/Softmax', 'index': 21, 'shape': array([ 1, 10], dtype=int32), 'dtype': <class 'numpy.uint8'>, 'quantization': (0.00390625, 0)}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16MsnRzrZ0Yk",
        "colab_type": "text"
      },
      "source": [
        "- I'm not sure how to use quantization attribute in input/output_details. But maybe\n",
        "  - If quantization attribute is (a, b), then the input data f should be transform to (f/a + b) and casted to uint8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_O6nfR4XCmo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def quantize(detail, data):\n",
        "    shape = detail['shape']\n",
        "    dtype = detail['dtype']\n",
        "    a, b = detail['quantization']\n",
        "    \n",
        "    return (data/a + b).astype(dtype).reshape(shape)\n",
        "\n",
        "\n",
        "def dequantize(detail, data):\n",
        "    a, b = detail['quantization']\n",
        "    \n",
        "    return (data - b)*a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJuqJna_vgna",
        "colab_type": "code",
        "outputId": "2f507230-b1ee-45d5-adbd-33130de36e4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "quantized_input = quantize(input_details[0], test_images[:1])\n",
        "interpreter.set_tensor(input_details[0]['index'], quantized_input)\n",
        "\n",
        "interpreter.invoke()\n",
        "\n",
        "# The results are stored on 'index' of output_details\n",
        "quantized_output = interpreter.get_tensor(output_details[0]['index'])\n",
        "\n",
        "print('sample result of quantized model')\n",
        "print(dequantize(output_details[0], quantized_output))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample result of quantized model\n",
            "[[0.00390625 0.0390625  0.06640625 0.1015625  0.015625   0.\n",
            "  0.76953125 0.00390625 0.00390625 0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rFwYYH5aZjy",
        "colab_type": "text"
      },
      "source": [
        "### Compile the tflite file using EdgeTPU Compiler "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmSX6C6RxAZh",
        "colab_type": "code",
        "outputId": "80731631-0a93-48cc-9733-dc13a0e060ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "%%bash\n",
        "\n",
        "edgetpu_compiler 'model.tflite'"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Edge TPU Compiler version 2.0.267685300\n",
            "\n",
            "Model compiled successfully in 35 ms.\n",
            "\n",
            "Input model: model.tflite\n",
            "Input size: 28.31KiB\n",
            "Output model: model_edgetpu.tflite\n",
            "Output size: 76.56KiB\n",
            "On-chip memory available for caching model parameters: 7.95MiB\n",
            "On-chip memory used for caching model parameters: 34.25KiB\n",
            "Off-chip memory used for streaming uncached model parameters: 1.50KiB\n",
            "Number of Edge TPU subgraphs: 1\n",
            "Total number of operations: 10\n",
            "Operation log: model_edgetpu.log\n",
            "See the operation log file for individual operation details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQ9qGJwZf_AV",
        "colab_type": "text"
      },
      "source": [
        "We can download the generated file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygUHjCLOz41Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('model_edgetpu.tflite')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMFiIwlk3r40",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}